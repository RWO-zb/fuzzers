Loading latest experiment, id=1
Layers [640, 500, 300]
nodel:
TapNet(
  (fc): Sequential(
    (0): Linear(in_features=300, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=512, out_features=256, bias=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=256, out_features=1, bias=True)
  )
  (lstm): LSTM(24, 256)
  (conv_1_models): ModuleList(
    (0-2): 3 x Conv1d(80, 256, kernel_size=(8,), stride=(1,))
  )
  (conv_bn_1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_2): Conv1d(256, 256, kernel_size=(5,), stride=(1,))
  (conv_bn_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_3): Conv1d(256, 128, kernel_size=(3,), stride=(1,))
  (conv_bn_3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (mapping): Sequential(
    (fc_0): Linear(in_features=640, out_features=500, bias=True)
    (bn_0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu_0): LeakyReLU(negative_slope=0.01)
    (fc_1): Linear(in_features=500, out_features=300, bias=True)
  )
  (att_models): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=300, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=1, bias=True)
    )
  )
)
mutate states  [3 2 1 2 3 2 2 3 2 2 1 2 3 2 3]
14.141288757324219 68.61503 82.75632 [False] 9.999006984206559e-05
mutate states  [3 2 3 3 3 2 2 3 3 2 3 1 2 3 2]
3.0889663696289062 82.15082 85.239784 [False] 1.6725864073526116e-25
mutate states  [3 1 2 2 3 3 1 3 3 3 3 2 1 2 1]
4.728137969970703 75.68596 85.142235 [False] 1.1184185313298362e-282
mutate states  [1 2 3 1 2 1 1 2 1 3 1 2 2 2 1]
